{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Prompt Design in Vertex AI: Challenge Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "## Install the Google Gen AI SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tFy3H3aPgx12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-00-c83baca456d5\"\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "T-tiytzQE0uM"
   },
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Put your Vertex AI Studio 'Image Analysis' code here\n",
    "\n",
    "**Important: Update Your Client Authentication**\n",
    "\n",
    "When you generate code from the Vertex AI Studio UI, it will use an **API Key** for authentication by default. That code block will look like this:\n",
    "\n",
    "```python\n",
    "# THIS IS THE DEFAULT CODE FROM THE UI\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    api_key=os.environ.get(\"GOOGLE_CLOUD_API_KEY\"),\n",
    ")\n",
    "```\n",
    "\n",
    "This lab environment does not use API keys. Instead, you must use the `PROJECT_ID` and `LOCATION` variables that were already defined in cell above.\n",
    "\n",
    "After you paste your code into the cell below, **find and replace** the `client` definition block with this one:\n",
    "\n",
    "```python\n",
    "# USE THIS CODE INSTEAD\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "\"Vibrant mountain path, wildflowers, backpack, map.\"\n",
      "```"
     ]
    }
   ],
   "source": [
    "# TODO: Put your Vertex AI Studio 'Image Analysis' code here.\n",
    "#\n",
    "# After you paste the code, be sure to find the `client = genai.Client(...)`\n",
    "# block and replace it with the project/location version as instructed above.\n",
    "#\n",
    "# --- PASTE YOUR CODE BELOW ---\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import base64\n",
    "import os\n",
    "\n",
    "def generate():\n",
    "  client = genai.Client(vertexai=True, project=\"qwiklabs-gcp-00-c83baca456d5\", location=\"us-west1\")\n",
    "\n",
    "  msg1_image1 = types.Part.from_uri(\n",
    "      file_uri=\"gs://qwiklabs-gcp-00-c83baca456d5-bucket/cymbal-product-image.png\",\n",
    "      mime_type=\"image/png\",\n",
    "  )\n",
    "  msg2_text1 = types.Part.from_text(text=\"\"\"**Visualizing the Scene**\n",
    "\n",
    "I'm concentrating on capturing the essence of the image, starting with the obvious. Right now, I'm focused on the visual elements: setting, path, and vegetation. I see the mountain trail, the sunny day, and the winding dirt path. The details will help me portray the overall mood, which is what I need to capture.\n",
    "\n",
    "\n",
    "**Deconstructing the Composition**\n",
    "\n",
    "I've broken down the image. I'm currently working on details like the backpack, map, and water bottle to add context. The sunlight and the angle of view are informing the mood of peace and adventure. The specific flowers are also taking shape in my mind, particularly the blue and yellow ones that caught my eye.\"\"\")\n",
    "  msg2_text2 = types.Part.from_text(text=\"\"\"This image captures a vibrant and inviting scene on a mountain hiking trail under bright sunshine. A narrow dirt path winds its way uphill, flanked by an abundance of lush green grass and a stunning variety of wildflowers.\n",
    "\n",
    "On the left side of the path, a dense cluster of colorful blooms features prominent bright blue flowers (possibly delphiniums or aconites), cheerful yellow flowers (some resembling daffodils), and striking red feathery blossoms. White flowers are also scattered among the greenery.\n",
    "\n",
    "To the right of the path, a blue hiking backpack rests on the grassy ground, with a teal-colored water bottle visible in one of its side pockets. Slightly further up the path and to the right, a folded map is spread open on the grass, suggesting navigation or a planning stop during the hike.\n",
    "\n",
    "The background shows more green, undulating slopes with scattered bushes, indicating a vast natural landscape. The clear lighting and vivid colors evoke a sense of serene natural beauty and the joy of outdoor adventure.\"\"\")\n",
    "\n",
    "  model = \"gemini-2.5-flash\"\n",
    "  contents = [\n",
    "    types.Content(\n",
    "      role=\"user\",\n",
    "      parts=[\n",
    "        msg1_image1,\n",
    "        types.Part.from_text(text=\"\"\"Subscribe to DR abhishek\"\"\")\n",
    "      ]\n",
    "    ),\n",
    "    types.Content(\n",
    "      role=\"model\",\n",
    "      parts=[\n",
    "        msg2_text1,\n",
    "        msg2_text2\n",
    "      ]\n",
    "    ),\n",
    "    types.Content(\n",
    "      role=\"user\",\n",
    "      parts=[\n",
    "        types.Part.from_text(text=\"\"\"Change the wording of the prompt in the code cell to make the output less than 10 words.\"\"\")\n",
    "      ]\n",
    "    ),\n",
    "  ]\n",
    "\n",
    "  generate_content_config = types.GenerateContentConfig(\n",
    "    temperature = 1,\n",
    "    top_p = 1,\n",
    "    max_output_tokens = 65535,\n",
    "    safety_settings = [types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "      threshold=\"OFF\"\n",
    "    )],\n",
    "    thinking_config=types.ThinkingConfig(\n",
    "      thinking_budget=-1,\n",
    "    ),\n",
    "  )\n",
    "\n",
    "  for chunk in client.models.generate_content_stream(\n",
    "    model = model,\n",
    "    contents = contents,\n",
    "    config = generate_content_config,\n",
    "    ):\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_genai_sdk.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
